<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
      <style>
          th:first-child, td:first-child {
              white-space: nowrap;
          }

          th:not(:first-child), td:not(:first-child) {
              word-wrap: break-word;
          }
      </style>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3 | Organizaci√≥n/Ciencia de Datos 7506-9558-TA047</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="C√°tedra Martinelli" />
<meta property="og:description" content="C√°tedra Martinelli" />
<link rel="canonical" href="https://organizacion-de-datos-7506-argerich.github.io/consigna_tp3_2c2025.html" />
<meta property="og:url" content="https://organizacion-de-datos-7506-argerich.github.io/consigna_tp3_2c2025.html" />
<meta property="og:site_name" content="Organizaci√≥n/Ciencia de Datos 7506-9558-TA047" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"C√°tedra Martinelli","headline":"Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3","url":"https://organizacion-de-datos-7506-argerich.github.io/consigna_tp3_2c2025.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=f8ac7521de4814f85cb172b17272b116fe09fe77">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3</h1>
      <h2 class="project-tagline">C√°tedra Martinelli</h2>
      
      
      
        <a href="/" class="btn">üè† Ir al inicio</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="ciencia-de-datos--trabajo-pr√°ctico-n¬∫-3">Ciencia de Datos ‚Äî Trabajo Pr√°ctico N.¬∫ 3</h1>
<h2 id="machine-learning">Machine Learning</h2>

<p>El tercer TP es una competencia de Machine Learning en donde cada alumno debe intentar determinar, para cada tweet brindado, si el mismo est√° basado en un hecho real o no.</p>

<p>La competencia se desarrolla en la plataforma de Kaggle  https://www.kaggle.com/c/nlp-getting-started.</p>

<p>El dataset consta de una serie de tweets, para los cuales se informa:</p>

<ul>
  <li>
    <p>id - identificador √∫nico para cada  tweet</p>
  </li>
  <li>
    <p>text - el texto del tweet</p>
  </li>
  <li>
    <p>location - ubicaci√≥n desde donde fue enviado (podr√≠a no estar)</p>
  </li>
  <li>
    <p>keyword - un keyword para el tweet  (podr√≠a faltar)</p>
  </li>
  <li>
    <p>target - en train.csv, indica si se trata de un desastre real  (1) o no (0)</p>
  </li>
</ul>

<p>Los submits con el resultado deben tener el formato:</p>

<ul>
  <li>Id: Un id num√©rico para identificar el tweet</li>
</ul>

<p>target: 1 / 0 seg√∫n se crea que el tweet se trata sobre un desastre real, o no.</p>

<p>Los alumnos deber√°n probar distintos algoritmos de Machine Learning para intentar predecir si el tweet est√° basado en hechos reales o no. A medida que realicen pruebas deben realizar el correspondiente submit en Kaggle para evaluar el resultado de los mismos.</p>

<hr />

<h2 id="parte-i-an√°lisis-exploratorio-2-puntos">Parte I: An√°lisis exploratorio (2 puntos)</h2>

<p>Realizar 6 visualizaciones interesantes que ayuden a explicar el target.</p>

<hr />

<h2 id="parte-ii-machine-learning-baseline-2-puntos">Parte II: Machine Learning Baseline (2 puntos)</h2>

<p>Vamos a construir un modelo muy sencillo para saber qu√© es lo peor que podemos hacer, en general esta es una tarea muy importante que queremos que repitan en sus proyectos de machine learning. ¬øPor qu√©?</p>

<ul>
  <li>
    <p>Navaja de Ockham: ‚ÄúCuando se ofrecen dos o m√°s explicaciones de un fen√≥meno, es preferible la explicaci√≥n completa m√°s simple; es decir, no deben multiplicarse las entidades sin necesidad.‚Äù ¬øPara qu√© desarrollar un modelo super complejo si capaz es peor o casi igual que uno muy sencillo?</p>
  </li>
  <li>
    <p>Nos sirve para saber si estamos usando bien los modelos m√°s complejos, si su score nos da peor al baseline probablemente se deba a un error de c√≥digo.</p>
  </li>
  <li>
    <p>Nos sirve para r√°pidamente saber que tan complejo es un problema.</p>
  </li>
  <li>
    <p>Los modelos simples son f√°ciles de entender.</p>
  </li>
</ul>

<p>Se deben crear al menos dos features num√©ricas y dos features categ√≥ricas para entrenar una regresi√≥n log√≠stica, utilizando b√∫squeda de hiperparametros, realizando los encodings correspondientes y garantizando la reproducibilidad de los resultados cuando el notebook corriera varias veces. A su vez, usar un embedding para el campo text.</p>

<p>Conteste las preguntas:</p>

<ul>
  <li>
    <p>¬øCu√°l es el mejor score de validaci√≥n obtenido? (¬øC√≥mo conviene obtener el dataset para validar?)</p>
  </li>
  <li>
    <p>Al predecir con este modelo para la competencia, ¬øC√∫al es el score obtenido? (guardar el csv con predicciones para entregarlo despu√©s)</p>
  </li>
  <li>
    <p>¬øQu√© features son los m√°s importantes para predecir con el mejor modelo? Graficar.</p>
  </li>
</ul>

<hr />

<h2 id="parte-iii-machine-learning-4-puntos">Parte III: Machine Learning (4 puntos)</h2>

<p>Entrenar 2 (de tipos distintos, excluyendo regresiones log√≠sticas) modelos (2 puntos cada uno) con b√∫squeda de hiperparametros (¬øc√≥mo conviene elegir los datos de validaci√≥n respecto de los de train?).</p>

<p>Los modelos deben cumplir las siguientes condiciones:</p>

<ul>
  <li>Deben utilizar F1 score como m√©trica de validaci√≥n.</li>
  <li>Deben medirse solo en validaci√≥n, no contra la competencia.</li>
  <li>Deben ser reproducibles (correr el notebook varias veces no afecta al resultado).</li>
  <li>Deben tener un score en validaci√≥n superior a 0,8.</li>
  <li>Para el feature engineering debe utilizarse mean encoding y one hot encoding al menos una vez cada uno.</li>
  <li>Se recomienda no limitarse a las features utilizadas previamente.</li>
</ul>

<p>Deber√°n contestar la siguiente pregunta:</p>
<ul>
  <li>Para el mejor modelo de ambos, ¬øcu√°l es el score en la competencia? (guardar el csv con predicciones para entregarlo despu√©s)</li>
</ul>

<hr />

<h2 id="parte-iv-consignas-adicionales-2-puntos">Parte IV: Consignas adicionales (2 puntos)</h2>

<p>Sumar al menos 2 puntos adicionales, realizando las consignas a continuaci√≥n que sean necesarias:</p>

<ul>
  <li>Conseguir un modelo que con 4 features supere 0.80 de F1 (1 punto)</li>
  <li>Entrenar una red neuronal con una layer LSTM (Long Short-Term Memory) o GRU con un score mayor a 0.80 (No se incluye en los dos modelos previos) (2 puntos)</li>
  <li>Resolver el problema realizando un embedding para el campo text y KNN (No se incluye en los dos modelos previos) (1 puntos)</li>
  <li>Realizar un embedding para el campo text y visualizarlo con alguna t√©cnica de reducci√≥n de visualizaciones distinta a PCA. En base a la visualizaci√≥n, ¬øSer√≠a posible predecir el target con este embedding? (2 punto)</li>
  <li>Graficar y analizar, para alguno de los modelos de la parte III, los siguientes resultados (1 punto):
    <ul>
      <li>Curva ROC, explicando la selecci√≥n de corte.</li>
      <li>Feature importance.</li>
      <li>Matriz de confusi√≥n.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="criterio-de-correcci√≥n">Criterio de correcci√≥n</h2>

<p>Se necesita un 60% (6/10) de los puntos para aprobar.</p>

<h3 id="parte-i">Parte I</h3>

<p>Cada visualizaci√≥n vale un punto, y debe cumplir con las siguientes condiciones:</p>
<ul>
  <li>Debe explicarse por s√≠ misma, sin necesidad de texto aclaratorio.</li>
  <li>Debe tener r√≥tulos en los ejes que corresponda y en el t√≠tulo (incluyendo unidades si corresponde).</li>
  <li>Debe mostrar una relaci√≥n con el target que sea clara.</li>
  <li>El uso del color debe ser intencional, elegido por ustedes, no por la librer√≠a.</li>
  <li>La visualizaci√≥n debe ser legible (Un bar chart de 40 barras por ejemplo es ilegible)</li>
  <li>Debe cumplir el objetivo propuesto</li>
</ul>

<h3 id="parte-ii">Parte II</h3>

<p>Vamos a corregir los siguientes puntos (no pueden restar m√°s de 2 en total):</p>
<ul>
  <li>Utiliza mal los datos de validaci√≥n ya sea para obtener el resultado o para buscar hiper par√°metros (-2 puntos), ejemplos: calcular el score con otras labels, calcular el score usando la predicci√≥n binaria y no la probabilidad, el set de validaci√≥n se usa para elegir los par√°metros pero tambi√©n est√° dentro del entrenamiento de cada modelo, el set de validaci√≥n se usa filtrando informaci√≥n a los encodings, etc.</li>
  <li>El modelo no est√° bien hecho (-2 puntos), ejemplo: entrenan con las labels o datos cambiados para algunas filas</li>
  <li>No es capaz de predecir para la competencia o no lo hace correctamente (-2 puntos)</li>
  <li>No es reproducible (-1 puntos)</li>
  <li>No obtiene bien los features m√°s importantes (-1 puntos)</li>
  <li>La predicci√≥n en la competencia da menos de 0.5 (-1 puntos)</li>
  <li>La predicci√≥n para la competencia tiene errores (-0.5 punto)</li>
  <li>No utiliza todos los features (-0.5 punto)</li>
</ul>

<h3 id="parte-iii">Parte III</h3>

<p>Vamos a corregir los siguientes puntos en cada modelo de 2 puntos (a medida se acumulan estos pueden hacer que el modelo valga 0, pero nunca negativo):</p>
<ul>
  <li>Para cada modelo cada condici√≥n no cumplida (o mal hecha) resta 0.5 puntos.</li>
  <li>Feature engineering inapropiado para el modelo elegido (-1 puntos), ejemplos: features que no est√°n normalizadas para una red neuronal, features sin ninguna consideraci√≥n de escalas para un KNN, etc.</li>
  <li>No buscan para todos los hiperparametros importantes (-1 puntos).</li>
</ul>

<p>Adem√°s si un modelo diera un resultado menor a 0,6 en validaci√≥n se invalida entero.
Por sobre el puntaje total del ejercicio (ambos modelos) se restan 2 puntos si cualquiera de las siguientes cosas suceden (no acumulables): eligen mal el mejor modelo entre los dos o la predicci√≥n para la competencia no est√° bien hecha o la predicci√≥n en la competencia da menos de 0.5.</p>

<h3 id="detalles-y-recomendaciones">Detalles y recomendaciones</h3>

<ul>
  <li>Para consultas conceptuales sobre machine learning o preguntas de consigna pueden consultar en el canal de slack #consultas-tp3.</li>
  <li>Para consultas de c√≥digo con su corrector o alg√∫n ayudante por privado.</li>
  <li>No deben buscar modelos entrenados por otros para usarlos, esto solo les puede jugar en contra porque es probable que no cumplan las condiciones pedidas, que no est√©n prolijos, que est√©n orientados a conseguir buenos resultados en la competencia (cosa que encima no evaluamos) y que tengan alg√∫n error conceptual.</li>
  <li>Recomendamos trabajar durante todo el TP en solo 4 notebooks: Uno de visualizaciones, otro para la regresi√≥n log√≠stica y uno para cada modelo de la parte III. Les recomendamos desarrollarlos de forma prolija y mostrar de forma ordenada cada uno de los resultados y pasos, con t√≠tulos y comentarios donde corresponda.</li>
  <li>El TP pide solo 6 visus y 3 modelos con condiciones muy claras, tengan esa consideraci√≥n a medida avanzan para chequear que cumplen todo.</li>
  <li>El TP no pide ni eval√∫a m√°s que lo que dice, si bien ser original y tener un buen score suma en t√©rminos de trabajo y aprendizaje para ustedes, sean inteligentes respecto a los modelos y features que eligen para trabajar para garantizar que pueden terminar. Ya van a tener tiempo de ser originales en el TP4‚Ä¶</li>
  <li>Particularmente este TP es muy dif√≠cil empezarlo al final, en cuotas se vuelve mucho m√°s sencillo, les recomendamos empezar por las visus que no necesitan teor√≠a nueva.</li>
  <li>Todos los puntos deben estar desarrollados.</li>
</ul>



      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
