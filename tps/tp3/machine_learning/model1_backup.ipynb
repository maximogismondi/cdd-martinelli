{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa91274",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd289148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar path para importar ml_utils\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "from ml_utils import evaluate_model, plot_feature_importance, compare_models, COLOR_NO_DISASTER, COLOR_DISASTER, COLOR_GENERAL\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388464f",
   "metadata": {},
   "source": [
    "## Cargar Datos Avanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d963236",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../.data/processed/\")\n",
    "\n",
    "# Cargar datos con features avanzadas\n",
    "train_df = pd.read_pickle(DATA_PATH / \"train_advanced.pkl\")\n",
    "\n",
    "print(f\"Train dataset: {train_df.shape}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "for i, col in enumerate(train_df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nDistribuci√≥n del target:\")\n",
    "print(train_df['target'].value_counts().sort_index())\n",
    "print(f\"\\nProporci√≥n de disasters: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb97dd",
   "metadata": {},
   "source": [
    "## Preparar Features\n",
    "\n",
    "Usaremos todas las features disponibles:\n",
    "- **Num√©ricas b√°sicas**: 7 features de texto (length, word_count, etc.)\n",
    "- **Num√©ricas avanzadas**: sentiment (2), linguistic (4), intensity (2), location (2) = 10 features\n",
    "- **Texto**: TF-IDF del texto lematizado\n",
    "- **Keywords**: OneHotEncoder de keywords\n",
    "- **Location v√°lida**: feature binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features num√©ricas b√°sicas\n",
    "numeric_features_basic = [\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'hashtag_count',\n",
    "    'mention_count',\n",
    "    'url_count',\n",
    "    'uppercase_percentage',\n",
    "    'punctuation_percentage'\n",
    "]\n",
    "\n",
    "# Features num√©ricas avanzadas\n",
    "numeric_features_advanced = [\n",
    "    'sentiment_polarity',\n",
    "    'sentiment_subjectivity',\n",
    "    'emoji_count',\n",
    "    'uppercase_word_count',\n",
    "    'lexical_diversity',\n",
    "    'number_count',\n",
    "    'urgency_word_count',\n",
    "    'intensity_word_count',\n",
    "    'has_valid_location'\n",
    "]\n",
    "\n",
    "# Location features (manejar NaN)\n",
    "location_features = ['location_lat', 'location_lon']\n",
    "\n",
    "# Combinar todas las num√©ricas\n",
    "numeric_features = numeric_features_basic + numeric_features_advanced\n",
    "\n",
    "print(f\"Features num√©ricas b√°sicas: {len(numeric_features_basic)}\")\n",
    "print(f\"Features num√©ricas avanzadas: {len(numeric_features_advanced)}\")\n",
    "print(f\"Features de location: {len(location_features)}\")\n",
    "print(f\"Total features num√©ricas: {len(numeric_features)}\")\n",
    "\n",
    "# Preparar datasets\n",
    "X_numeric = train_df[numeric_features]\n",
    "X_location = train_df[location_features].fillna(-999)  # Valor especial para missing locations\n",
    "X_text = train_df['text_lemmatized'].fillna('')\n",
    "X_keyword = train_df[['keyword_clean']].fillna('unknown')\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_numeric: {X_numeric.shape}\")\n",
    "print(f\"  X_location: {X_location.shape}\")\n",
    "print(f\"  X_text: {X_text.shape}\")\n",
    "print(f\"  X_keyword: {X_keyword.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6337f",
   "metadata": {},
   "source": [
    "## Split Train/Validation\n",
    "\n",
    "80/20 split estratificado para mantener proporci√≥n de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices\n",
    "X_numeric_train, X_numeric_val, \\\n",
    "X_location_train, X_location_val, \\\n",
    "X_text_train, X_text_val, \\\n",
    "X_keyword_train, X_keyword_val, \\\n",
    "y_train, y_val = train_test_split(\n",
    "    X_numeric, X_location, X_text, X_keyword, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(y_train)} samples\")\n",
    "print(f\"Val set: {len(y_val)} samples\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b97f2",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline\n",
    "\n",
    "1. StandardScaler para features num√©ricas\n",
    "2. TfidfVectorizer para texto (max 100 features)\n",
    "3. OneHotEncoder para keywords (max 100 categor√≠as)\n",
    "4. Combinar todo en una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalar num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_val_scaled = scaler.transform(X_numeric_val)\n",
    "\n",
    "# 2. Location ya est√° preparada (fillna con -999)\n",
    "X_location_train_scaled = scaler.fit_transform(X_location_train)\n",
    "X_location_val_scaled = scaler.transform(X_location_val)\n",
    "\n",
    "# 3. TF-IDF para texto\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)  # unigrams y bigrams\n",
    ")\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train).toarray()\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val).toarray()\n",
    "\n",
    "# 4. OneHotEncoder para keywords\n",
    "onehot_encoder = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    handle_unknown='infrequent_if_exist',\n",
    "    max_categories=100\n",
    ")\n",
    "X_keyword_train_encoded = onehot_encoder.fit_transform(X_keyword_train)\n",
    "X_keyword_val_encoded = onehot_encoder.transform(X_keyword_val)\n",
    "\n",
    "print(\"Features transformadas:\")\n",
    "print(f\"  Num√©ricas escaladas: {X_numeric_train_scaled.shape}\")\n",
    "print(f\"  Location escaladas: {X_location_train_scaled.shape}\")\n",
    "print(f\"  TF-IDF (texto + bigrams): {X_text_train_tfidf.shape}\")\n",
    "print(f\"  OneHot (keywords): {X_keyword_train_encoded.shape}\")\n",
    "\n",
    "# 5. Combinar todas las features\n",
    "X_train_combined = np.hstack([\n",
    "    X_numeric_train_scaled,\n",
    "    X_location_train_scaled,\n",
    "    X_text_train_tfidf,\n",
    "    X_keyword_train_encoded\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_numeric_val_scaled,\n",
    "    X_location_val_scaled,\n",
    "    X_text_val_tfidf,\n",
    "    X_keyword_val_encoded\n",
    "])\n",
    "\n",
    "print(\"\\n‚úÖ Features combinadas:\")\n",
    "print(f\"  Train: {X_train_combined.shape}\")\n",
    "print(f\"  Validation: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9281f",
   "metadata": {},
   "source": [
    "## GridSearchCV - B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Buscaremos los mejores hiperpar√°metros para Random Forest:\n",
    "- **n_estimators**: n√∫mero de √°rboles\n",
    "- **max_depth**: profundidad m√°xima\n",
    "- **min_samples_split**: m√≠nimo de samples para split\n",
    "- **min_samples_leaf**: m√≠nimo de samples en hoja\n",
    "- **max_features**: n√∫mero de features por split\n",
    "\n",
    "Usaremos F1 Score como m√©trica de evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47686220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grid de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV con 5-fold cross-validation\n",
    "print(\"Iniciando GridSearchCV...\")\n",
    "print(f\"Combinaciones a probar: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ed9ee",
   "metadata": {},
   "source": [
    "## Resultados de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor F1 Score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nüìã Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Top 5 configuraciones\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(f\"\\nüîù Top 5 Configuraciones:\")\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n  F1 Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b687c",
   "metadata": {},
   "source": [
    "## Entrenar Modelo Final con Mejores Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejor modelo\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Modelo final: {best_rf}\")\n",
    "print(f\"\\nN√∫mero de features utilizadas: {X_train_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0ce86",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f96b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir\n",
    "y_pred_val = best_rf.predict(X_val_combined)\n",
    "\n",
    "# Evaluar usando ml_utils\n",
    "results_rf = evaluate_model(y_val, y_pred_val, \"Random Forest (Best from GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7ca5",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Random Forest proporciona importancia de features basada en Gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba05136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir nombres de features\n",
    "feature_names = []\n",
    "\n",
    "# Num√©ricas\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# Location\n",
    "feature_names.extend(['location_lat', 'location_lon'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_names = [f\"text_{word}\" for word in tfidf.get_feature_names_out()]\n",
    "feature_names.extend(tfidf_names)\n",
    "\n",
    "# Keywords\n",
    "keyword_names = [f\"keyword_{cat.replace('keyword_clean_', '')}\" \n",
    "                 for cat in onehot_encoder.get_feature_names_out()]\n",
    "feature_names.extend(keyword_names)\n",
    "\n",
    "print(f\"Total feature names: {len(feature_names)}\")\n",
    "print(f\"Total features en modelo: {len(best_rf.feature_importances_)}\")\n",
    "\n",
    "# Verificar que coinciden\n",
    "assert len(feature_names) == len(best_rf.feature_importances_), \\\n",
    "    \"Mismatch entre feature names y feature importances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6282b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar funci√≥n de ml_utils para graficar\n",
    "importance_df = plot_feature_importance(\n",
    "    feature_names,\n",
    "    best_rf.feature_importances_,\n",
    "    \"Random Forest\",\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"\\nüîù Top 10 Features M√°s Importantes:\")\n",
    "print(importance_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081ef31",
   "metadata": {},
   "source": [
    "## An√°lisis de Overfitting\n",
    "\n",
    "Comparar performance en train vs validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en train\n",
    "y_pred_train = best_rf.predict(X_train_combined)\n",
    "\n",
    "# Evaluar (sin imprimir)\n",
    "results_train = evaluate_model(y_train, y_pred_train, print_results=False)\n",
    "results_val = evaluate_model(y_val, y_pred_val, print_results=False)\n",
    "\n",
    "# Comparar\n",
    "comparison = pd.DataFrame({\n",
    "    'Train': results_train,\n",
    "    'Validation': results_val,\n",
    "    'Diferencia': {k: results_train[k] - results_val[k] for k in results_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN TRAIN vs VALIDATION\".center(60))\n",
    "print(\"=\" * 60)\n",
    "print(comparison.T.to_string())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis\n",
    "diff_f1 = results_train['f1'] - results_val['f1']\n",
    "if diff_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Posible overfitting detectado (diferencia F1: {diff_f1:.4f})\")\n",
    "elif diff_f1 < 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Performance mejor en validaci√≥n que train (diferencia F1: {diff_f1:.4f})\")\n",
    "    print(\"   Esto puede indicar que el validation set es m√°s f√°cil.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Buen balance entre train y validation (diferencia F1: {diff_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1e22f",
   "metadata": {},
   "source": [
    "## Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN: RANDOM FOREST CON GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"  F1 Score (CV):         {grid_search.best_score_:.4f}\")\n",
    "print(f\"  F1 Score (Train):      {results_train['f1']:.4f}\")\n",
    "print(f\"  F1 Score (Validation): {results_val['f1']:.4f}  ‚≠ê\")\n",
    "\n",
    "print(f\"\\nüéØ Target: F1 > 0.80\")\n",
    "if results_val['f1'] > 0.80:\n",
    "    print(f\"  ‚úÖ OBJETIVO CUMPLIDO (F1 = {results_val['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Por debajo del objetivo (F1 = {results_val['f1']:.4f})\")\n",
    "    print(f\"     Falta: {0.80 - results_val['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Configuraci√≥n:\")\n",
    "print(f\"  Algoritmo: Random Forest\")\n",
    "print(f\"  Features totales: {X_train_combined.shape[1]}\")\n",
    "print(f\"  B√∫squeda: GridSearchCV (5-fold CV)\")\n",
    "print(f\"  Combinaciones probadas: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443a105",
   "metadata": {},
   "source": [
    "## Predicciones para Competencia\n",
    "\n",
    "Generamos predicciones en el test set para Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar test\n",
    "test_df = pd.read_pickle(DATA_PATH / \"test_advanced.pkl\")\n",
    "\n",
    "print(f\"Test dataset: {test_df.shape}\")\n",
    "\n",
    "# Preparar features igual que train\n",
    "X_test_numeric = test_df[numeric_features]\n",
    "X_test_location = test_df[location_features].fillna(-999)\n",
    "X_test_text = test_df['text_lemmatized'].fillna('')\n",
    "X_test_keyword = test_df[['keyword_clean']].fillna('unknown')\n",
    "\n",
    "# Transformar\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_location_scaled = scaler.transform(X_test_location)\n",
    "X_test_text_tfidf = tfidf.transform(X_test_text).toarray()\n",
    "X_test_keyword_encoded = onehot_encoder.transform(X_test_keyword)\n",
    "\n",
    "# Combinar\n",
    "X_test_combined = np.hstack([\n",
    "    X_test_numeric_scaled,\n",
    "    X_test_location_scaled,\n",
    "    X_test_text_tfidf,\n",
    "    X_test_keyword_encoded\n",
    "])\n",
    "\n",
    "print(f\"Test features combinadas: {X_test_combined.shape}\")\n",
    "\n",
    "# Predecir\n",
    "test_predictions = best_rf.predict(X_test_combined)\n",
    "\n",
    "print(f\"\\nPredicciones generadas: {len(test_predictions)}\")\n",
    "print(f\"Distribuci√≥n de predicciones:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear submission\n",
    "test_raw = pd.read_csv(Path(\"../.data/raw/\") / \"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "OUTPUT_PATH = Path(\"../.data/submissions/\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_file = OUTPUT_PATH / \"model1_random_forest.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission guardado en: {submission_file}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n√öltimas 5 filas:\")\n",
    "print(submission.tail())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
