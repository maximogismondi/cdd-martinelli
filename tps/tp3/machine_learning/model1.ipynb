{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa91274",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb572c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34efc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar path para importar ml_utils\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "from ml_utils import evaluate_model, plot_feature_importance, compare_models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11e9fd",
   "metadata": {},
   "source": [
    "## Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../.data/processed/\")\n",
    "\n",
    "train_df = pd.read_pickle(DATA_PATH / \"train.pkl\")\n",
    "\n",
    "print(f\"Train dataset: {train_df.shape}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "for i, col in enumerate(train_df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nDistribuci√≥n del target:\")\n",
    "print(train_df['target'].value_counts().sort_index())\n",
    "print(f\"\\nProporci√≥n de disasters: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de467eb",
   "metadata": {},
   "source": [
    "## Preparar Features\n",
    "\n",
    "Usaremos:\n",
    "- **7 features num√©ricas**: text_length, word_count, hashtag_count, mention_count, url_count, uppercase_percentage, punctuation_percentage\n",
    "- **TF-IDF**: 100 features del texto lematizado (incluye bigrams)\n",
    "- **OneHot**: ~100 categor√≠as de keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features num√©ricas\n",
    "numeric_features = [\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'hashtag_count',\n",
    "    'mention_count',\n",
    "    'url_count',\n",
    "    'uppercase_percentage',\n",
    "    'punctuation_percentage'\n",
    "]\n",
    "\n",
    "print(f\"Features num√©ricas: {len(numeric_features)}\")\n",
    "\n",
    "# Preparar datasets\n",
    "X_numeric = train_df[numeric_features]\n",
    "X_text = train_df['text_lemmatized'].fillna('')\n",
    "X_keyword = train_df[['keyword_clean']].fillna('unknown')\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_numeric: {X_numeric.shape}\")\n",
    "print(f\"  X_text: {X_text.shape}\")\n",
    "print(f\"  X_keyword: {X_keyword.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b104eb3",
   "metadata": {},
   "source": [
    "## Split Train/Validation\n",
    "\n",
    "80/20 split estratificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8771f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_numeric_train, X_numeric_val, \\\n",
    "X_text_train, X_text_val, \\\n",
    "X_keyword_train, X_keyword_val, \\\n",
    "y_train, y_val = train_test_split(\n",
    "    X_numeric, X_text, X_keyword, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(y_train)} samples\")\n",
    "print(f\"Val set: {len(y_val)} samples\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236ba1c",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline\n",
    "\n",
    "1. StandardScaler para features num√©ricas\n",
    "2. TfidfVectorizer para texto (max 100 features, bigrams)\n",
    "3. OneHotEncoder para keywords (max 100 categor√≠as)\n",
    "4. Combinar todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea20a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalar num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_val_scaled = scaler.transform(X_numeric_val)\n",
    "\n",
    "# 2. TF-IDF para texto (incluye bigrams)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)  # unigrams y bigrams\n",
    ")\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train).toarray()\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val).toarray()\n",
    "\n",
    "# 3. OneHotEncoder para keywords\n",
    "onehot_encoder = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    handle_unknown='infrequent_if_exist',\n",
    "    max_categories=100\n",
    ")\n",
    "X_keyword_train_encoded = onehot_encoder.fit_transform(X_keyword_train)\n",
    "X_keyword_val_encoded = onehot_encoder.transform(X_keyword_val)\n",
    "\n",
    "print(\"Features transformadas:\")\n",
    "print(f\"  Num√©ricas escaladas: {X_numeric_train_scaled.shape}\")\n",
    "print(f\"  TF-IDF (texto + bigrams): {X_text_train_tfidf.shape}\")\n",
    "print(f\"  OneHot (keywords): {X_keyword_train_encoded.shape}\")\n",
    "\n",
    "# 4. Combinar\n",
    "X_train_combined = np.hstack([\n",
    "    X_numeric_train_scaled,\n",
    "    X_text_train_tfidf,\n",
    "    X_keyword_train_encoded\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_numeric_val_scaled,\n",
    "    X_text_val_tfidf,\n",
    "    X_keyword_val_encoded\n",
    "])\n",
    "\n",
    "print(\"\\n‚úÖ Features combinadas:\")\n",
    "print(f\"  Train: {X_train_combined.shape}\")\n",
    "print(f\"  Validation: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118b1b",
   "metadata": {},
   "source": [
    "## GridSearchCV - B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Buscaremos los mejores hiperpar√°metros para Random Forest.\n",
    "Usaremos F1 Score como m√©trica de evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV con 5-fold cross-validation\n",
    "print(\"Iniciando GridSearchCV...\")\n",
    "print(f\"Combinaciones a probar: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"‚ö†Ô∏è Esto puede tomar 10-30 minutos...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7758fb1",
   "metadata": {},
   "source": [
    "## Resultados de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor F1 Score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nüìã Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Top 5 configuraciones\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(f\"\\nüîù Top 5 Configuraciones:\")\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n  F1 Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e986ce",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "y_pred_val = best_rf.predict(X_val_combined)\n",
    "\n",
    "# Evaluar\n",
    "results_rf = evaluate_model(y_val, y_pred_val, \"Random Forest (Best from GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b3a2b",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67147e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir nombres de features\n",
    "feature_names = []\n",
    "\n",
    "# Num√©ricas\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_names = [f\"text_{word}\" for word in tfidf.get_feature_names_out()]\n",
    "feature_names.extend(tfidf_names)\n",
    "\n",
    "# Keywords\n",
    "keyword_names = [f\"keyword_{cat.replace('keyword_clean_', '')}\" \n",
    "                 for cat in onehot_encoder.get_feature_names_out()]\n",
    "feature_names.extend(keyword_names)\n",
    "\n",
    "print(f\"Total feature names: {len(feature_names)}\")\n",
    "print(f\"Total features en modelo: {len(best_rf.feature_importances_)}\")\n",
    "\n",
    "# Verificar\n",
    "assert len(feature_names) == len(best_rf.feature_importances_), \\\n",
    "    \"Mismatch entre feature names y feature importances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar importancia\n",
    "importance_df = plot_feature_importance(\n",
    "    feature_names,\n",
    "    best_rf.feature_importances_,\n",
    "    \"Random Forest\",\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"\\nüîù Top 10 Features M√°s Importantes:\")\n",
    "print(importance_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d5a68",
   "metadata": {},
   "source": [
    "## An√°lisis de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c177852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en train\n",
    "y_pred_train = best_rf.predict(X_train_combined)\n",
    "\n",
    "# Evaluar (sin imprimir)\n",
    "results_train = evaluate_model(y_train, y_pred_train, print_results=False)\n",
    "results_val = evaluate_model(y_val, y_pred_val, print_results=False)\n",
    "\n",
    "# Comparar\n",
    "comparison = pd.DataFrame({\n",
    "    'Train': results_train,\n",
    "    'Validation': results_val,\n",
    "    'Diferencia': {k: results_train[k] - results_val[k] for k in results_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN TRAIN vs VALIDATION\".center(60))\n",
    "print(\"=\" * 60)\n",
    "print(comparison.T.to_string())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis\n",
    "diff_f1 = results_train['f1'] - results_val['f1']\n",
    "if diff_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Posible overfitting detectado (diferencia F1: {diff_f1:.4f})\")\n",
    "elif diff_f1 < 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Performance mejor en validaci√≥n que train (diferencia F1: {diff_f1:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Buen balance entre train y validation (diferencia F1: {diff_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5699903",
   "metadata": {},
   "source": [
    "## Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN: RANDOM FOREST CON GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"  F1 Score (CV):         {grid_search.best_score_:.4f}\")\n",
    "print(f\"  F1 Score (Train):      {results_train['f1']:.4f}\")\n",
    "print(f\"  F1 Score (Validation): {results_val['f1']:.4f}  ‚≠ê\")\n",
    "\n",
    "print(f\"\\nüéØ Target: F1 > 0.80\")\n",
    "if results_val['f1'] > 0.80:\n",
    "    print(f\"  ‚úÖ OBJETIVO CUMPLIDO (F1 = {results_val['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Por debajo del objetivo (F1 = {results_val['f1']:.4f})\")\n",
    "    print(f\"     Falta: {0.80 - results_val['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Configuraci√≥n:\")\n",
    "print(f\"  Algoritmo: Random Forest\")\n",
    "print(f\"  Features totales: {X_train_combined.shape[1]}\")\n",
    "print(f\"  B√∫squeda: GridSearchCV (5-fold CV)\")\n",
    "print(f\"  Combinaciones probadas: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dabb1",
   "metadata": {},
   "source": [
    "## Predicciones para Competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e36b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar test\n",
    "test_df = pd.read_pickle(DATA_PATH / \"test.pkl\")\n",
    "\n",
    "print(f\"Test dataset: {test_df.shape}\")\n",
    "\n",
    "# Preparar features\n",
    "X_test_numeric = test_df[numeric_features]\n",
    "X_test_text = test_df['text_lemmatized'].fillna('')\n",
    "X_test_keyword = test_df[['keyword_clean']].fillna('unknown')\n",
    "\n",
    "# Transformar\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_text_tfidf = tfidf.transform(X_test_text).toarray()\n",
    "X_test_keyword_encoded = onehot_encoder.transform(X_test_keyword)\n",
    "\n",
    "# Combinar\n",
    "X_test_combined = np.hstack([\n",
    "    X_test_numeric_scaled,\n",
    "    X_test_text_tfidf,\n",
    "    X_test_keyword_encoded\n",
    "])\n",
    "\n",
    "print(f\"Test features combinadas: {X_test_combined.shape}\")\n",
    "\n",
    "# Predecir\n",
    "test_predictions = best_rf.predict(X_test_combined)\n",
    "\n",
    "print(f\"\\nPredicciones generadas: {len(test_predictions)}\")\n",
    "print(f\"Distribuci√≥n de predicciones:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb48c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear submission\n",
    "test_raw = pd.read_csv(Path(\"../.data/raw/\") / \"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "OUTPUT_PATH = Path(\"../.data/submissions/\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_file = OUTPUT_PATH / \"model1_random_forest.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission guardado en: {submission_file}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n√öltimas 5 filas:\")\n",
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd289148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar path para importar ml_utils\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "from ml_utils import evaluate_model, plot_feature_importance, compare_models, COLOR_NO_DISASTER, COLOR_DISASTER, COLOR_GENERAL\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388464f",
   "metadata": {},
   "source": [
    "## Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d963236",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../.data/processed/train_advanced.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m DATA_PATH = Path(\u001b[33m\"\u001b[39m\u001b[33m../.data/processed/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Cargar datos con features avanzadas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_advanced.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mColumnas disponibles:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/fiuba/alumno/cdd-martinelli/venv/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/fiuba/alumno/cdd-martinelli/venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../.data/processed/train_advanced.pkl'"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../.data/processed/\")\n",
    "\n",
    "# Cargar datos b√°sicos\n",
    "train_df = pd.read_pickle(DATA_PATH / \"train.pkl\")\n",
    "\n",
    "print(f\"Train dataset: {train_df.shape}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "for i, col in enumerate(train_df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nDistribuci√≥n del target:\")\n",
    "print(train_df['target'].value_counts().sort_index())\n",
    "print(f\"\\nProporci√≥n de disasters: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb97dd",
   "metadata": {},
   "source": [
    "## Preparar Features\n",
    "\n",
    "Usaremos las features b√°sicas disponibles:\n",
    "- **Num√©ricas b√°sicas**: 7 features de texto (length, word_count, etc.)\n",
    "- **Texto**: TF-IDF del texto lematizado  \n",
    "- **Keywords**: OneHotEncoder de keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features num√©ricas b√°sicas\n",
    "numeric_features = [\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'hashtag_count',\n",
    "    'mention_count',\n",
    "    'url_count',\n",
    "    'uppercase_percentage',\n",
    "    'punctuation_percentage'\n",
    "]\n",
    "\n",
    "print(f\"Features num√©ricas: {len(numeric_features)}\")\n",
    "\n",
    "# Preparar datasets\n",
    "X_numeric = train_df[numeric_features]\n",
    "X_text = train_df['text_lemmatized'].fillna('')\n",
    "X_keyword = train_df[['keyword_clean']].fillna('unknown')\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_numeric: {X_numeric.shape}\")\n",
    "print(f\"  X_text: {X_text.shape}\")\n",
    "print(f\"  X_keyword: {X_keyword.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6337f",
   "metadata": {},
   "source": [
    "## Split Train/Validation\n",
    "\n",
    "80/20 split estratificado para mantener proporci√≥n de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices\n",
    "X_numeric_train, X_numeric_val, \\\n",
    "X_location_train, X_location_val, \\\n",
    "X_text_train, X_text_val, \\\n",
    "X_keyword_train, X_keyword_val, \\\n",
    "y_train, y_val = train_test_split(\n",
    "    X_numeric, X_location, X_text, X_keyword, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(y_train)} samples\")\n",
    "print(f\"Val set: {len(y_val)} samples\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b97f2",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline\n",
    "\n",
    "1. StandardScaler para features num√©ricas\n",
    "2. TfidfVectorizer para texto (max 100 features)\n",
    "3. OneHotEncoder para keywords (max 100 categor√≠as)\n",
    "4. Combinar todo en una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalar num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_val_scaled = scaler.transform(X_numeric_val)\n",
    "\n",
    "# 2. Location ya est√° preparada (fillna con -999)\n",
    "X_location_train_scaled = scaler.fit_transform(X_location_train)\n",
    "X_location_val_scaled = scaler.transform(X_location_val)\n",
    "\n",
    "# 3. TF-IDF para texto\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)  # unigrams y bigrams\n",
    ")\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train).toarray()\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val).toarray()\n",
    "\n",
    "# 4. OneHotEncoder para keywords\n",
    "onehot_encoder = OneHotEncoder(\n",
    "    sparse_output=False,\n",
    "    handle_unknown='infrequent_if_exist',\n",
    "    max_categories=100\n",
    ")\n",
    "X_keyword_train_encoded = onehot_encoder.fit_transform(X_keyword_train)\n",
    "X_keyword_val_encoded = onehot_encoder.transform(X_keyword_val)\n",
    "\n",
    "print(\"Features transformadas:\")\n",
    "print(f\"  Num√©ricas escaladas: {X_numeric_train_scaled.shape}\")\n",
    "print(f\"  Location escaladas: {X_location_train_scaled.shape}\")\n",
    "print(f\"  TF-IDF (texto + bigrams): {X_text_train_tfidf.shape}\")\n",
    "print(f\"  OneHot (keywords): {X_keyword_train_encoded.shape}\")\n",
    "\n",
    "# 5. Combinar todas las features\n",
    "X_train_combined = np.hstack([\n",
    "    X_numeric_train_scaled,\n",
    "    X_location_train_scaled,\n",
    "    X_text_train_tfidf,\n",
    "    X_keyword_train_encoded\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_numeric_val_scaled,\n",
    "    X_location_val_scaled,\n",
    "    X_text_val_tfidf,\n",
    "    X_keyword_val_encoded\n",
    "])\n",
    "\n",
    "print(\"\\n‚úÖ Features combinadas:\")\n",
    "print(f\"  Train: {X_train_combined.shape}\")\n",
    "print(f\"  Validation: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9281f",
   "metadata": {},
   "source": [
    "## GridSearchCV - B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Buscaremos los mejores hiperpar√°metros para Random Forest:\n",
    "- **n_estimators**: n√∫mero de √°rboles\n",
    "- **max_depth**: profundidad m√°xima\n",
    "- **min_samples_split**: m√≠nimo de samples para split\n",
    "- **min_samples_leaf**: m√≠nimo de samples en hoja\n",
    "- **max_features**: n√∫mero de features por split\n",
    "\n",
    "Usaremos F1 Score como m√©trica de evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47686220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grid de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV con 5-fold cross-validation\n",
    "print(\"Iniciando GridSearchCV...\")\n",
    "print(f\"Combinaciones a probar: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ed9ee",
   "metadata": {},
   "source": [
    "## Resultados de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor F1 Score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nüìã Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Top 5 configuraciones\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(f\"\\nüîù Top 5 Configuraciones:\")\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n  F1 Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b687c",
   "metadata": {},
   "source": [
    "## Entrenar Modelo Final con Mejores Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejor modelo\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Modelo final: {best_rf}\")\n",
    "print(f\"\\nN√∫mero de features utilizadas: {X_train_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0ce86",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f96b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir\n",
    "y_pred_val = best_rf.predict(X_val_combined)\n",
    "\n",
    "# Evaluar usando ml_utils\n",
    "results_rf = evaluate_model(y_val, y_pred_val, \"Random Forest (Best from GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7ca5",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Random Forest proporciona importancia de features basada en Gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba05136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir nombres de features\n",
    "feature_names = []\n",
    "\n",
    "# Num√©ricas\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# Location\n",
    "feature_names.extend(['location_lat', 'location_lon'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_names = [f\"text_{word}\" for word in tfidf.get_feature_names_out()]\n",
    "feature_names.extend(tfidf_names)\n",
    "\n",
    "# Keywords\n",
    "keyword_names = [f\"keyword_{cat.replace('keyword_clean_', '')}\" \n",
    "                 for cat in onehot_encoder.get_feature_names_out()]\n",
    "feature_names.extend(keyword_names)\n",
    "\n",
    "print(f\"Total feature names: {len(feature_names)}\")\n",
    "print(f\"Total features en modelo: {len(best_rf.feature_importances_)}\")\n",
    "\n",
    "# Verificar que coinciden\n",
    "assert len(feature_names) == len(best_rf.feature_importances_), \\\n",
    "    \"Mismatch entre feature names y feature importances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6282b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar funci√≥n de ml_utils para graficar\n",
    "importance_df = plot_feature_importance(\n",
    "    feature_names,\n",
    "    best_rf.feature_importances_,\n",
    "    \"Random Forest\",\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"\\nüîù Top 10 Features M√°s Importantes:\")\n",
    "print(importance_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081ef31",
   "metadata": {},
   "source": [
    "## An√°lisis de Overfitting\n",
    "\n",
    "Comparar performance en train vs validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en train\n",
    "y_pred_train = best_rf.predict(X_train_combined)\n",
    "\n",
    "# Evaluar (sin imprimir)\n",
    "results_train = evaluate_model(y_train, y_pred_train, print_results=False)\n",
    "results_val = evaluate_model(y_val, y_pred_val, print_results=False)\n",
    "\n",
    "# Comparar\n",
    "comparison = pd.DataFrame({\n",
    "    'Train': results_train,\n",
    "    'Validation': results_val,\n",
    "    'Diferencia': {k: results_train[k] - results_val[k] for k in results_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN TRAIN vs VALIDATION\".center(60))\n",
    "print(\"=\" * 60)\n",
    "print(comparison.T.to_string())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis\n",
    "diff_f1 = results_train['f1'] - results_val['f1']\n",
    "if diff_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Posible overfitting detectado (diferencia F1: {diff_f1:.4f})\")\n",
    "elif diff_f1 < 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Performance mejor en validaci√≥n que train (diferencia F1: {diff_f1:.4f})\")\n",
    "    print(\"   Esto puede indicar que el validation set es m√°s f√°cil.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Buen balance entre train y validation (diferencia F1: {diff_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1e22f",
   "metadata": {},
   "source": [
    "## Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN: RANDOM FOREST CON GRIDSEARCHCV\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"  F1 Score (CV):         {grid_search.best_score_:.4f}\")\n",
    "print(f\"  F1 Score (Train):      {results_train['f1']:.4f}\")\n",
    "print(f\"  F1 Score (Validation): {results_val['f1']:.4f}  ‚≠ê\")\n",
    "\n",
    "print(f\"\\nüéØ Target: F1 > 0.80\")\n",
    "if results_val['f1'] > 0.80:\n",
    "    print(f\"  ‚úÖ OBJETIVO CUMPLIDO (F1 = {results_val['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Por debajo del objetivo (F1 = {results_val['f1']:.4f})\")\n",
    "    print(f\"     Falta: {0.80 - results_val['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Configuraci√≥n:\")\n",
    "print(f\"  Algoritmo: Random Forest\")\n",
    "print(f\"  Features totales: {X_train_combined.shape[1]}\")\n",
    "print(f\"  B√∫squeda: GridSearchCV (5-fold CV)\")\n",
    "print(f\"  Combinaciones probadas: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443a105",
   "metadata": {},
   "source": [
    "## Predicciones para Competencia\n",
    "\n",
    "Generamos predicciones en el test set para Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar test\n",
    "test_df = pd.read_pickle(DATA_PATH / \"test_advanced.pkl\")\n",
    "\n",
    "print(f\"Test dataset: {test_df.shape}\")\n",
    "\n",
    "# Preparar features igual que train\n",
    "X_test_numeric = test_df[numeric_features]\n",
    "X_test_location = test_df[location_features].fillna(-999)\n",
    "X_test_text = test_df['text_lemmatized'].fillna('')\n",
    "X_test_keyword = test_df[['keyword_clean']].fillna('unknown')\n",
    "\n",
    "# Transformar\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_location_scaled = scaler.transform(X_test_location)\n",
    "X_test_text_tfidf = tfidf.transform(X_test_text).toarray()\n",
    "X_test_keyword_encoded = onehot_encoder.transform(X_test_keyword)\n",
    "\n",
    "# Combinar\n",
    "X_test_combined = np.hstack([\n",
    "    X_test_numeric_scaled,\n",
    "    X_test_location_scaled,\n",
    "    X_test_text_tfidf,\n",
    "    X_test_keyword_encoded\n",
    "])\n",
    "\n",
    "print(f\"Test features combinadas: {X_test_combined.shape}\")\n",
    "\n",
    "# Predecir\n",
    "test_predictions = best_rf.predict(X_test_combined)\n",
    "\n",
    "print(f\"\\nPredicciones generadas: {len(test_predictions)}\")\n",
    "print(f\"Distribuci√≥n de predicciones:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear submission\n",
    "test_raw = pd.read_csv(Path(\"../.data/raw/\") / \"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "OUTPUT_PATH = Path(\"../.data/submissions/\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_file = OUTPUT_PATH / \"model1_random_forest.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission guardado en: {submission_file}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n√öltimas 5 filas:\")\n",
    "print(submission.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
