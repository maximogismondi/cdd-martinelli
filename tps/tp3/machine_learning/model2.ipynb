{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d09eb1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306e5d8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar path para importar ml_utils\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "from ml_utils import evaluate_model, plot_feature_importance, compare_models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ff38",
   "metadata": {},
   "source": [
    "## Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12967c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../.data/processed/\")\n",
    "\n",
    "train_df = pd.read_pickle(DATA_PATH / \"train.pkl\")\n",
    "\n",
    "print(f\"Train dataset: {train_df.shape}\")\n",
    "print(f\"\\nDistribuci√≥n del target:\")\n",
    "print(train_df['target'].value_counts().sort_index())\n",
    "print(f\"\\nProporci√≥n de disasters: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9488d01",
   "metadata": {},
   "source": [
    "## Preparar Features\n",
    "\n",
    "Usaremos:\n",
    "- **7 features num√©ricas**: text_length, word_count, hashtag_count, mention_count, url_count, uppercase_percentage, punctuation_percentage\n",
    "- **TF-IDF**: 150 features del texto lematizado (incluye bigrams)\n",
    "- **Mean Encoding**: 1 feature codificando keywords por su relaci√≥n con el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features num√©ricas\n",
    "numeric_features = [\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'hashtag_count',\n",
    "    'mention_count',\n",
    "    'url_count',\n",
    "    'uppercase_percentage',\n",
    "    'punctuation_percentage'\n",
    "]\n",
    "\n",
    "print(f\"Features num√©ricas: {len(numeric_features)}\")\n",
    "\n",
    "# Preparar datasets\n",
    "X_numeric = train_df[numeric_features]\n",
    "X_text = train_df['text_lemmatized'].fillna('')\n",
    "X_keyword = train_df['keyword_clean'].fillna('unknown')\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_numeric: {X_numeric.shape}\")\n",
    "print(f\"  X_text: {X_text.shape}\")\n",
    "print(f\"  X_keyword: {X_keyword.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51a676",
   "metadata": {},
   "source": [
    "## Split Train/Validation\n",
    "\n",
    "80/20 split estratificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6070b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices - primero separamos los √≠ndices\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(train_df)),\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Ahora separamos usando los √≠ndices\n",
    "X_numeric_train = X_numeric.iloc[train_idx]\n",
    "X_numeric_val = X_numeric.iloc[val_idx]\n",
    "\n",
    "X_text_train = X_text.iloc[train_idx]\n",
    "X_text_val = X_text.iloc[val_idx]\n",
    "\n",
    "X_keyword_train = X_keyword.iloc[train_idx]\n",
    "X_keyword_val = X_keyword.iloc[val_idx]\n",
    "\n",
    "y_train = y.iloc[train_idx]\n",
    "y_val = y.iloc[val_idx]\n",
    "\n",
    "print(f\"Train set: {len(y_train)} samples\")\n",
    "print(f\"Val set: {len(y_val)} samples\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd756d7",
   "metadata": {},
   "source": [
    "## Mean Encoding para Keywords\n",
    "\n",
    "El **Mean Encoding** (Target Encoding) reemplaza cada categor√≠a por la media del target para esa categor√≠a.\n",
    "\n",
    "Ventajas vs OneHot:\n",
    "- Reduce dimensionalidad (1 columna vs N columnas)\n",
    "- Captura relaci√≥n directa con el target\n",
    "- Funciona mejor con XGBoost\n",
    "\n",
    "‚ö†Ô∏è Importante: Solo calculamos las medias en el train set para evitar data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189adb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular mean encoding en train\n",
    "keyword_means = train_df.iloc[train_idx].groupby('keyword_clean')['target'].mean()\n",
    "\n",
    "print(\"Mean Encoding por Keyword (Top 10):\")\n",
    "print(keyword_means.sort_values(ascending=False).head(10))\n",
    "print(\"\\nKeywords con menor mean (Top 10):\")\n",
    "print(keyword_means.sort_values().head(10))\n",
    "\n",
    "# Aplicar encoding\n",
    "# Usar media global como default para keywords no vistos\n",
    "global_mean = y_train.mean()\n",
    "\n",
    "X_keyword_train_encoded = X_keyword_train.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "X_keyword_val_encoded = X_keyword_val.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "\n",
    "print(f\"\\n‚úÖ Mean Encoding aplicado\")\n",
    "print(f\"  Train shape: {X_keyword_train_encoded.shape}\")\n",
    "print(f\"  Val shape: {X_keyword_val_encoded.shape}\")\n",
    "print(f\"  Global mean (para keywords no vistos): {global_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d5678",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline\n",
    "\n",
    "1. StandardScaler para features num√©ricas\n",
    "2. TfidfVectorizer para texto (max 150 features, bigrams)\n",
    "3. Mean Encoding para keywords (ya aplicado)\n",
    "4. Combinar todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83972eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalar num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_val_scaled = scaler.transform(X_numeric_val)\n",
    "\n",
    "# 2. TF-IDF para texto (m√°s features que Model 1)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=150,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)  # unigrams y bigrams\n",
    ")\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train).toarray()\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val).toarray()\n",
    "\n",
    "print(\"Features transformadas:\")\n",
    "print(f\"  Num√©ricas escaladas: {X_numeric_train_scaled.shape}\")\n",
    "print(f\"  TF-IDF (texto + bigrams): {X_text_train_tfidf.shape}\")\n",
    "print(f\"  Mean Encoding (keywords): {X_keyword_train_encoded.shape}\")\n",
    "\n",
    "# 3. Combinar\n",
    "X_train_combined = np.hstack([\n",
    "    X_numeric_train_scaled,\n",
    "    X_text_train_tfidf,\n",
    "    X_keyword_train_encoded\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_numeric_val_scaled,\n",
    "    X_text_val_tfidf,\n",
    "    X_keyword_val_encoded\n",
    "])\n",
    "\n",
    "print(\"\\n‚úÖ Features combinadas:\")\n",
    "print(f\"  Train: {X_train_combined.shape}\")\n",
    "print(f\"  Validation: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002430fb",
   "metadata": {},
   "source": [
    "## GridSearchCV - B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Buscaremos los mejores hiperpar√°metros para XGBoost.\n",
    "Usaremos un grid reducido para hacer pruebas m√°s r√°pidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de hiperpar√°metros (reducido para demo)\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0, 0.1],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1]\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV con 5-fold cross-validation\n",
    "print(\"Iniciando GridSearchCV para XGBoost...\")\n",
    "print(f\"Combinaciones a probar: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"‚ö†Ô∏è Esto puede tomar 15-30 minutos...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d25df8",
   "metadata": {},
   "source": [
    "## Resultados de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fdcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE GRIDSEARCHCV - XGBOOST\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor F1 Score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nüìã Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Top 5 configuraciones\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(f\"\\nüîù Top 5 Configuraciones:\")\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n  F1 Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6b517",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "y_pred_val = best_xgb.predict(X_val_combined)\n",
    "\n",
    "# Evaluar\n",
    "results_xgb = evaluate_model(y_val, y_pred_val, \"XGBoost (Best from GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132838a",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "XGBoost proporciona importancia basada en ganancia (gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir nombres de features\n",
    "feature_names = []\n",
    "\n",
    "# Num√©ricas\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_names = [f\"text_{word}\" for word in tfidf.get_feature_names_out()]\n",
    "feature_names.extend(tfidf_names)\n",
    "\n",
    "# Mean Encoding (1 feature)\n",
    "feature_names.append('keyword_mean_encoding')\n",
    "\n",
    "print(f\"Total feature names: {len(feature_names)}\")\n",
    "print(f\"Total features en modelo: {X_train_combined.shape[1]}\")\n",
    "\n",
    "# Verificar\n",
    "assert len(feature_names) == X_train_combined.shape[1], \\\n",
    "    \"Mismatch entre feature names y n√∫mero de features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancia por ganancia\n",
    "importance = best_xgb.get_booster().get_score(importance_type='gain')\n",
    "\n",
    "# Convertir a array (usar 0 si feature no aparece)\n",
    "importance_array = np.array([importance.get(f'f{i}', 0) for i in range(len(feature_names))])\n",
    "\n",
    "# Graficar\n",
    "importance_df = plot_feature_importance(\n",
    "    feature_names,\n",
    "    importance_array,\n",
    "    \"XGBoost\",\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"\\nüîù Top 10 Features M√°s Importantes:\")\n",
    "print(importance_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034bf976",
   "metadata": {},
   "source": [
    "## An√°lisis de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en train\n",
    "y_pred_train = best_xgb.predict(X_train_combined)\n",
    "\n",
    "# Evaluar (sin imprimir)\n",
    "results_train = evaluate_model(y_train, y_pred_train, print_results=False)\n",
    "results_val = evaluate_model(y_val, y_pred_val, print_results=False)\n",
    "\n",
    "# Comparar\n",
    "comparison = pd.DataFrame({\n",
    "    'Train': results_train,\n",
    "    'Validation': results_val,\n",
    "    'Diferencia': {k: results_train[k] - results_val[k] for k in results_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN TRAIN vs VALIDATION\".center(60))\n",
    "print(\"=\" * 60)\n",
    "print(comparison.T.to_string())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis\n",
    "diff_f1 = results_train['f1'] - results_val['f1']\n",
    "if diff_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Posible overfitting detectado (diferencia F1: {diff_f1:.4f})\")\n",
    "elif diff_f1 < 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Performance mejor en validaci√≥n que train (diferencia F1: {diff_f1:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Buen balance entre train y validation (diferencia F1: {diff_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b271e",
   "metadata": {},
   "source": [
    "## Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e50435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN: XGBOOST CON GRIDSEARCHCV Y MEAN ENCODING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"  F1 Score (CV):         {grid_search.best_score_:.4f}\")\n",
    "print(f\"  F1 Score (Train):      {results_train['f1']:.4f}\")\n",
    "print(f\"  F1 Score (Validation): {results_val['f1']:.4f}  ‚≠ê\")\n",
    "\n",
    "print(f\"\\nüéØ Target: F1 > 0.80\")\n",
    "if results_val['f1'] > 0.80:\n",
    "    print(f\"  ‚úÖ OBJETIVO CUMPLIDO (F1 = {results_val['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Por debajo del objetivo (F1 = {results_val['f1']:.4f})\")\n",
    "    print(f\"     Falta: {0.80 - results_val['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Configuraci√≥n:\")\n",
    "print(f\"  Algoritmo: XGBoost (Gradient Boosting)\")\n",
    "print(f\"  Features totales: {X_train_combined.shape[1]}\")\n",
    "print(f\"  Encoding keywords: Mean Encoding (Target Encoding)\")\n",
    "print(f\"  B√∫squeda: GridSearchCV (5-fold CV)\")\n",
    "print(f\"  Combinaciones probadas: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a5551",
   "metadata": {},
   "source": [
    "## Predicciones para Competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar test\n",
    "test_df = pd.read_pickle(DATA_PATH / \"test.pkl\")\n",
    "\n",
    "print(f\"Test dataset: {test_df.shape}\")\n",
    "\n",
    "# Preparar features\n",
    "X_test_numeric = test_df[numeric_features]\n",
    "X_test_text = test_df['text_lemmatized'].fillna('')\n",
    "X_test_keyword = test_df['keyword_clean'].fillna('unknown')\n",
    "\n",
    "# Transformar\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_text_tfidf = tfidf.transform(X_test_text).toarray()\n",
    "X_test_keyword_encoded = X_test_keyword.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "\n",
    "# Combinar\n",
    "X_test_combined = np.hstack([\n",
    "    X_test_numeric_scaled,\n",
    "    X_test_text_tfidf,\n",
    "    X_test_keyword_encoded\n",
    "])\n",
    "\n",
    "print(f\"Test features combinadas: {X_test_combined.shape}\")\n",
    "\n",
    "# Predecir\n",
    "test_predictions = best_xgb.predict(X_test_combined)\n",
    "\n",
    "print(f\"\\nPredicciones generadas: {len(test_predictions)}\")\n",
    "print(f\"Distribuci√≥n de predicciones:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a923267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear submission\n",
    "test_raw = pd.read_csv(Path(\"../.data/raw/\") / \"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "OUTPUT_PATH = Path(\"../.data/submissions/\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_file = OUTPUT_PATH / \"model2_xgboost.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission guardado en: {submission_file}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n√öltimas 5 filas:\")\n",
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef41a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar path para importar ml_utils\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "from ml_utils import evaluate_model, plot_feature_importance, compare_models, COLOR_NO_DISASTER, COLOR_DISASTER, COLOR_GENERAL\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6066fc6",
   "metadata": {},
   "source": [
    "## Cargar Datos Avanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2badc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../.data/processed/\")\n",
    "\n",
    "# Cargar datos con features avanzadas\n",
    "train_df = pd.read_pickle(DATA_PATH / \"train_advanced.pkl\")\n",
    "\n",
    "print(f\"Train dataset: {train_df.shape}\")\n",
    "print(f\"\\nDistribuci√≥n del target:\")\n",
    "print(train_df['target'].value_counts().sort_index())\n",
    "print(f\"\\nProporci√≥n de disasters: {train_df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb0902",
   "metadata": {},
   "source": [
    "## Preparar Features\n",
    "\n",
    "Usaremos las mismas features que en Model 1, pero con **Mean Encoding** para keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63100e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features num√©ricas b√°sicas\n",
    "numeric_features_basic = [\n",
    "    'text_length',\n",
    "    'word_count',\n",
    "    'hashtag_count',\n",
    "    'mention_count',\n",
    "    'url_count',\n",
    "    'uppercase_percentage',\n",
    "    'punctuation_percentage'\n",
    "]\n",
    "\n",
    "# Features num√©ricas avanzadas\n",
    "numeric_features_advanced = [\n",
    "    'sentiment_polarity',\n",
    "    'sentiment_subjectivity',\n",
    "    'emoji_count',\n",
    "    'uppercase_word_count',\n",
    "    'lexical_diversity',\n",
    "    'number_count',\n",
    "    'urgency_word_count',\n",
    "    'intensity_word_count',\n",
    "    'has_valid_location'\n",
    "]\n",
    "\n",
    "# Location features\n",
    "location_features = ['location_lat', 'location_lon']\n",
    "\n",
    "# Combinar todas las num√©ricas\n",
    "numeric_features = numeric_features_basic + numeric_features_advanced\n",
    "\n",
    "print(f\"Features num√©ricas: {len(numeric_features)}\")\n",
    "print(f\"Features de location: {len(location_features)}\")\n",
    "\n",
    "# Preparar datasets\n",
    "X_numeric = train_df[numeric_features]\n",
    "X_location = train_df[location_features].fillna(-999)\n",
    "X_text = train_df['text_lemmatized'].fillna('')\n",
    "X_keyword = train_df['keyword_clean'].fillna('unknown')\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_numeric: {X_numeric.shape}\")\n",
    "print(f\"  X_location: {X_location.shape}\")\n",
    "print(f\"  X_text: {X_text.shape}\")\n",
    "print(f\"  X_keyword: {X_keyword.shape}\")\n",
    "print(f\"  y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360cc32",
   "metadata": {},
   "source": [
    "## Split Train/Validation\n",
    "\n",
    "80/20 split estratificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices - primero separamos los √≠ndices\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(train_df)),\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Ahora separamos todo usando los √≠ndices\n",
    "X_numeric_train = X_numeric.iloc[train_idx]\n",
    "X_numeric_val = X_numeric.iloc[val_idx]\n",
    "\n",
    "X_location_train = X_location.iloc[train_idx]\n",
    "X_location_val = X_location.iloc[val_idx]\n",
    "\n",
    "X_text_train = X_text.iloc[train_idx]\n",
    "X_text_val = X_text.iloc[val_idx]\n",
    "\n",
    "X_keyword_train = X_keyword.iloc[train_idx]\n",
    "X_keyword_val = X_keyword.iloc[val_idx]\n",
    "\n",
    "y_train = y.iloc[train_idx]\n",
    "y_val = y.iloc[val_idx]\n",
    "\n",
    "print(f\"Train set: {len(y_train)} samples\")\n",
    "print(f\"Val set: {len(y_val)} samples\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535cdd6",
   "metadata": {},
   "source": [
    "## Mean Encoding para Keywords\n",
    "\n",
    "El **Mean Encoding** (Target Encoding) reemplaza cada categor√≠a por la media del target para esa categor√≠a.\n",
    "\n",
    "Ventajas vs OneHot:\n",
    "- Reduce dimensionalidad (1 columna vs N columnas)\n",
    "- Captura relaci√≥n directa con el target\n",
    "- Funciona mejor con XGBoost\n",
    "\n",
    "‚ö†Ô∏è Importante: Solo calculamos las medias en el train set para evitar data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular mean encoding en train\n",
    "keyword_means = train_df.iloc[train_idx].groupby('keyword_clean')['target'].mean()\n",
    "\n",
    "print(\"Mean Encoding por Keyword:\")\n",
    "print(keyword_means.sort_values(ascending=False).head(10))\n",
    "print(\"\\nKeywords con menor mean:\")\n",
    "print(keyword_means.sort_values().head(10))\n",
    "\n",
    "# Aplicar encoding\n",
    "# Usar media global como default para keywords no vistos\n",
    "global_mean = y_train.mean()\n",
    "\n",
    "X_keyword_train_encoded = X_keyword_train.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "X_keyword_val_encoded = X_keyword_val.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "\n",
    "print(f\"\\n‚úÖ Mean Encoding aplicado\")\n",
    "print(f\"  Train shape: {X_keyword_train_encoded.shape}\")\n",
    "print(f\"  Val shape: {X_keyword_val_encoded.shape}\")\n",
    "print(f\"  Global mean (para keywords no vistos): {global_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fcacee",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline\n",
    "\n",
    "1. StandardScaler para features num√©ricas\n",
    "2. TfidfVectorizer para texto (max 150 features, incluyendo bigrams)\n",
    "3. Mean Encoding para keywords (ya aplicado)\n",
    "4. Combinar todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e79037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Escalar num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_val_scaled = scaler.transform(X_numeric_val)\n",
    "\n",
    "# 2. Location\n",
    "location_scaler = StandardScaler()\n",
    "X_location_train_scaled = location_scaler.fit_transform(X_location_train)\n",
    "X_location_val_scaled = location_scaler.transform(X_location_val)\n",
    "\n",
    "# 3. TF-IDF para texto (m√°s features que en Model 1)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=150,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)  # unigrams y bigrams\n",
    ")\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train).toarray()\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val).toarray()\n",
    "\n",
    "print(\"Features transformadas:\")\n",
    "print(f\"  Num√©ricas escaladas: {X_numeric_train_scaled.shape}\")\n",
    "print(f\"  Location escaladas: {X_location_train_scaled.shape}\")\n",
    "print(f\"  TF-IDF (texto + bigrams): {X_text_train_tfidf.shape}\")\n",
    "print(f\"  Mean Encoding (keywords): {X_keyword_train_encoded.shape}\")\n",
    "\n",
    "# 4. Combinar todas las features\n",
    "X_train_combined = np.hstack([\n",
    "    X_numeric_train_scaled,\n",
    "    X_location_train_scaled,\n",
    "    X_text_train_tfidf,\n",
    "    X_keyword_train_encoded\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_numeric_val_scaled,\n",
    "    X_location_val_scaled,\n",
    "    X_text_val_tfidf,\n",
    "    X_keyword_val_encoded\n",
    "])\n",
    "\n",
    "print(\"\\n‚úÖ Features combinadas:\")\n",
    "print(f\"  Train: {X_train_combined.shape}\")\n",
    "print(f\"  Validation: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ac03d",
   "metadata": {},
   "source": [
    "## GridSearchCV - B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Buscaremos los mejores hiperpar√°metros para XGBoost:\n",
    "- **n_estimators**: n√∫mero de boosting rounds\n",
    "- **max_depth**: profundidad m√°xima de √°rboles\n",
    "- **learning_rate**: tasa de aprendizaje\n",
    "- **subsample**: fracci√≥n de muestras por √°rbol\n",
    "- **colsample_bytree**: fracci√≥n de features por √°rbol\n",
    "- **gamma**: m√≠nima reducci√≥n de loss para split\n",
    "- **reg_alpha**: regularizaci√≥n L1\n",
    "- **reg_lambda**: regularizaci√≥n L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grid de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV con 5-fold cross-validation\n",
    "print(\"Iniciando GridSearchCV para XGBoost...\")\n",
    "print(f\"Combinaciones totales: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"‚ö†Ô∏è NOTA: Esto puede tomar MUCHO tiempo. Reduciendo grid para demo...\")\n",
    "\n",
    "# Grid reducido para demo (comentar esto y usar param_grid completo si tienes tiempo)\n",
    "param_grid_reduced = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0, 0.1],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1]\n",
    "}\n",
    "\n",
    "print(f\"Usando grid reducido: {np.prod([len(v) for v in param_grid_reduced.values()])} combinaciones\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid_reduced,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ GridSearchCV completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348197f",
   "metadata": {},
   "source": [
    "## Resultados de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90db3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTADOS DE GRIDSEARCHCV - XGBOOST\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor F1 Score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nüìã Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Top 5 configuraciones\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "print(f\"\\nüîù Top 5 Configuraciones:\")\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n  F1 Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Params: {row['params']}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564eec7",
   "metadata": {},
   "source": [
    "## Entrenar Modelo Final con Mejores Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejor modelo\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Modelo final: {best_xgb}\")\n",
    "print(f\"\\nN√∫mero de features utilizadas: {X_train_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f094a6",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir\n",
    "y_pred_val = best_xgb.predict(X_val_combined)\n",
    "\n",
    "# Evaluar usando ml_utils\n",
    "results_xgb = evaluate_model(y_val, y_pred_val, \"XGBoost (Best from GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2b699",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "XGBoost proporciona importancia basada en ganancia (gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir nombres de features\n",
    "feature_names = []\n",
    "\n",
    "# Num√©ricas\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# Location\n",
    "feature_names.extend(['location_lat', 'location_lon'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_names = [f\"text_{word}\" for word in tfidf.get_feature_names_out()]\n",
    "feature_names.extend(tfidf_names)\n",
    "\n",
    "# Mean Encoding (1 feature)\n",
    "feature_names.append('keyword_mean_encoding')\n",
    "\n",
    "print(f\"Total feature names: {len(feature_names)}\")\n",
    "print(f\"Total features en modelo: {X_train_combined.shape[1]}\")\n",
    "\n",
    "# Verificar\n",
    "assert len(feature_names) == X_train_combined.shape[1], \\\n",
    "    \"Mismatch entre feature names y n√∫mero de features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b42a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancia por ganancia\n",
    "importance = best_xgb.get_booster().get_score(importance_type='gain')\n",
    "\n",
    "# Convertir a array (usar 0 si feature no aparece)\n",
    "importance_array = np.array([importance.get(f'f{i}', 0) for i in range(len(feature_names))])\n",
    "\n",
    "# Usar funci√≥n de ml_utils para graficar\n",
    "importance_df = plot_feature_importance(\n",
    "    feature_names,\n",
    "    importance_array,\n",
    "    \"XGBoost\",\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"\\nüîù Top 10 Features M√°s Importantes:\")\n",
    "print(importance_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356a242",
   "metadata": {},
   "source": [
    "## An√°lisis de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2609d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en train\n",
    "y_pred_train = best_xgb.predict(X_train_combined)\n",
    "\n",
    "# Evaluar (sin imprimir)\n",
    "results_train = evaluate_model(y_train, y_pred_train, print_results=False)\n",
    "results_val = evaluate_model(y_val, y_pred_val, print_results=False)\n",
    "\n",
    "# Comparar\n",
    "comparison = pd.DataFrame({\n",
    "    'Train': results_train,\n",
    "    'Validation': results_val,\n",
    "    'Diferencia': {k: results_train[k] - results_val[k] for k in results_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN TRAIN vs VALIDATION\".center(60))\n",
    "print(\"=\" * 60)\n",
    "print(comparison.T.to_string())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis\n",
    "diff_f1 = results_train['f1'] - results_val['f1']\n",
    "if diff_f1 > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è Posible overfitting detectado (diferencia F1: {diff_f1:.4f})\")\n",
    "elif diff_f1 < 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Performance mejor en validaci√≥n que train (diferencia F1: {diff_f1:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Buen balance entre train y validation (diferencia F1: {diff_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69894441",
   "metadata": {},
   "source": [
    "## Resumen del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56534210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN: XGBOOST CON GRIDSEARCHCV Y MEAN ENCODING\".center(70))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"  F1 Score (CV):         {grid_search.best_score_:.4f}\")\n",
    "print(f\"  F1 Score (Train):      {results_train['f1']:.4f}\")\n",
    "print(f\"  F1 Score (Validation): {results_val['f1']:.4f}  ‚≠ê\")\n",
    "\n",
    "print(f\"\\nüéØ Target: F1 > 0.80\")\n",
    "if results_val['f1'] > 0.80:\n",
    "    print(f\"  ‚úÖ OBJETIVO CUMPLIDO (F1 = {results_val['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Por debajo del objetivo (F1 = {results_val['f1']:.4f})\")\n",
    "    print(f\"     Falta: {0.80 - results_val['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Configuraci√≥n:\")\n",
    "print(f\"  Algoritmo: XGBoost (Gradient Boosting)\")\n",
    "print(f\"  Features totales: {X_train_combined.shape[1]}\")\n",
    "print(f\"  Encoding keywords: Mean Encoding (Target Encoding)\")\n",
    "print(f\"  B√∫squeda: GridSearchCV (5-fold CV)\")\n",
    "print(f\"  Combinaciones probadas: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejores hiperpar√°metros:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f58e3",
   "metadata": {},
   "source": [
    "## Predicciones para Competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar test\n",
    "test_df = pd.read_pickle(DATA_PATH / \"test_advanced.pkl\")\n",
    "\n",
    "print(f\"Test dataset: {test_df.shape}\")\n",
    "\n",
    "# Preparar features\n",
    "X_test_numeric = test_df[numeric_features]\n",
    "X_test_location = test_df[location_features].fillna(-999)\n",
    "X_test_text = test_df['text_lemmatized'].fillna('')\n",
    "X_test_keyword = test_df['keyword_clean'].fillna('unknown')\n",
    "\n",
    "# Transformar\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_location_scaled = location_scaler.transform(X_test_location)\n",
    "X_test_text_tfidf = tfidf.transform(X_test_text).toarray()\n",
    "X_test_keyword_encoded = X_test_keyword.map(keyword_means).fillna(global_mean).values.reshape(-1, 1)\n",
    "\n",
    "# Combinar\n",
    "X_test_combined = np.hstack([\n",
    "    X_test_numeric_scaled,\n",
    "    X_test_location_scaled,\n",
    "    X_test_text_tfidf,\n",
    "    X_test_keyword_encoded\n",
    "])\n",
    "\n",
    "print(f\"Test features combinadas: {X_test_combined.shape}\")\n",
    "\n",
    "# Predecir\n",
    "test_predictions = best_xgb.predict(X_test_combined)\n",
    "\n",
    "print(f\"\\nPredicciones generadas: {len(test_predictions)}\")\n",
    "print(f\"Distribuci√≥n de predicciones:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56860049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear submission\n",
    "test_raw = pd.read_csv(Path(\"../.data/raw/\") / \"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "OUTPUT_PATH = Path(\"../.data/submissions/\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_file = OUTPUT_PATH / \"model2_xgboost.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission guardado en: {submission_file}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n√öltimas 5 filas:\")\n",
    "print(submission.tail())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
